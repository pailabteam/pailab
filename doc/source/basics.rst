Basics
======================



Building blocks
------------------------
pailab's core is the :py:class:`pailab.ml_repo.repo.MLRepo` class which is what we call the machine learning repository.
The repository stores and versions all objects needed in the machine learning development cycle. 
There are three fundamental differences to version control systems such as git or svn for classical software development:

- Instead of source code, objects are checked into the repository. Here, each object must inherit or at least implement the respective methods 
  from :py:class:`pailab.ml_repo.repo_objects.RepoObject` so that it can be handled by the repository. Furthermore, each such object belongs to a 
  certain category (:py:class:`pailab.ml_repo.repo.MLObjectType`), so that the repository may perform certain checks and allow to automatize the ml build pipeline. 

- Each object is split into a part with standard data and a part with (large) numerical data and both parts are stored separately in different storages.
  Here, the normal data is stored in a storage derived from :py:class:`pailab.ml_repo.repo_store.RepoStore` whereas the numerical 
  data is stored via a :py:class:`pailab.ml_repo.repo_store.NumpyStore`.

- The execution of different jobs such as model training and evaluation or error computation is triggered via the MLRepo. 
  Here, the MLRepo simply uses a JobRunner to execute the jobs.

As we see, we need three ingredients to initialize an MLRepo:

- RepoStore (handles the object data)
- NumpyStore (handles numpy part of the object data)
- JobHandler (runs the jobs such as training or evaluation)

basic functionality
--------------------------------------
The MLRepo offers four main functionalities

- Adding objects :py:meth:`pailab.ml_repo.repo.MLRepo.add`
- Retrieving objects :py:meth:`pailab.ml_repo.repo.MLRepo.get`
- Running Jobs (which are also objects from the repo perspective and therefore stored in the repo) :py:meth:`pailab.ml_repo.repo.MLRepo.run`
- Listing objects by their category :py:meth:`pailab.ml_repo.repo.MLRepo.get_names`

All other methods are just using these methods and provide a little bit more convenience in daily work.

Add objects
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
When adding an object to the repository the MLRepo automatically adds additional information to the object, stored in the attribute repo_info. 
The repo_info attribute is an instance of the :py:meth:`pailab.ml_repo.repo_objects.RepoInfo` and contains informations such as the version number
(this number is autogenerated from MLRepo), the objects name, a descripton of the object, a commit message, the author i.e. the user who added the object. 
So to add an object to an instance ml_repo of the MLRepo class you just call::

    ml_repo.add(obj, message = "just an example")

which adds the object where ``message`` is attached to the object in the ``repo_info`` attribute as well. Note that the method returns the version which was attached 
to the object so that::

    version = ml_repo.add(obj, message = "just an example")

``version`` contains the version number after the execution.

We can also add multiple objects at the same time storing them in a list, that is::

    versions = ml_repo.add([obj1, obj2], message = "just an example")

where ``version`` is now a list of versions for the different objects added.

Get objects
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
To retrieve objects from the storage one can use the :py:meth:`pailab.ml_repo.repo.MLRepo.get` method. Here, different possibilities 
to specify what object to get exist.
If one wants to retrieve a special version of an object you can call get with the object's name and the specified version::

    obj = ml_repo.get('obj_name', version = 'aasfdg-111-ezrhf')

If one wants to retrieve the first or last version, instead of typing the specific cryptic version string, we may use the keywords
:py:attr:`repo_store.repo.RepoStore.LAST_VERSION` and :py:attr:`repo_store.repo.RepoStore.FIRST_VERSION`::

        obj = ml_repo.get('obj_name', version = RepoStore.FIRST_VERSION)
    
returns the first version of the object with name ``obj_name``. Instead of specifying a single version, we can also retrieve a bunch of different versions just 
using a list of versions::
    
    objs = ml_repo.get('obj_name', version = ['aasfdg-111-ezrhf', RepoStore.FIRST_VERSION])

returns a list of the different versions of the object with name ``obj_name``.


Another frequent use case is to retrieve an object that has been created using a different object with a specific version. 
For exampl, you may be interested to get mean squared error (mse) for a specific model. Then, you can just use get to retrieve 
the mse object containing the mse for the specified model by calling get specifying the modifier_versions::

    obj = ml_reo.get('obj_name', version=None,  modifier_versions={'obj2_name': 'aasfdg-111-ezrhf'})

which returns the object with name obj_name and the version which has been constructed using the object 'obj2_name' with the specified version.
Analogously to above one can also ask for all objects which haven been constructed using an object with object's version in a list of specified versions, i.e.::

    objs = ml_reo.get('obj_name', version=None,  modifier_versions={'obj2_name': ['aasfdg-111-ezrhf', 'bbhuuu-123-ooo'})


.. IMPORTANT::

    If an object does not exist, the method may either throw an exception or return an empty list, depending on the argument **throw_error_not_exist**, i.e.::
        
        obj = ml_repo.get('obj_name', version = 'aasfdg-111-ezrhf', throw_error_not_exist = True)

    throws an exception if an object with this name and version does not exist. 

If we just want to check if exactly one object with a specified version or modification information exists, we may call the method setting the 
argument ``throw_error_not_unique`` to ``True``, which means that an exception is thrown if there are more then one obecjts satisfying the condition.


As we have discussed, an object is split into two parts that are stored separately: The 'small' data and the 'big' data of the object. 
By default, the get method returns the object leaving out the big data part. If one wants to get the complete object, one must 
set the argument ``full_object`` to ``True``::

    ml_repo.get('obj_name', version = 'aasfdg-111-ezrhf', full_object = True)

Getting names
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
To list al objects of a certain category stored in the repo, we can use :py:meth:`pailab.ml_repo.repo.MLRepo.get_names`::, e.g. to get the ids of all
testdata objects in the repo

    names = ml_repo.get_names(MLObjectType.TEST_DATA)

Running Jobs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
All functions which may be called from the MLRepo, e.g. the function to train a certain model,  are also objects which are stored within the repo.
Typically, these objects inherit from the :py:class:`pailab.ml_repo.repo.MLRepo.Job`. To run such a job using the repo, you can use 
:py:meth:`pailab.repo.MLRepo.run` method::

    job_info = ml_repo.run(job)

This line of code will add the Job object ``job`` to the repo and then call the ``add`` method of the ml_repo's internal ``JobRunner``. The ``job_info`` 
variable will either be a tuple of the job's name and the job's version number in the repo or a string containing a message that no input data 
has been changed since last run of the job.

.. NOTE::

    Before the ``run`` method adds the job to the repo, it checks if the job has a method ``check_rerun`` and if so, calls it to decide if the job really has to be
    executed (if the method returns ``True``). If the result of ``check_rerun`` is ``False``, the method does not run the job.

.. TIP::

    Note that for many situations such as training or evaluating a model there are respective methods wrapping 
    :py:meth:`pailab.ml_repo.repo.MLRepo.run` which should be preferred.
    However, all these method will, after creation of the needed ``Job`` object,  at the end call ``run``. 


Setting up an MLRepo
------------------------------

In-memory
~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The easiest way to start using pailab is instantiate MLRepo using all defaults, except the user which must be specified, otherwise an exception is thrown.

.. literalinclude:: ../../tests/repo_test.py
    :language: python
    :start-after: example with default
    :end-before: end example with default

This results in an MLRepo that handles everything in memory only, using  :py:class:`pailab.ml_repo.memory_handler.RepoObjectMemoryStorage` and :py:class:`pailab.ml_repo.memory_handler.NumpyMemoryStorage`
so that after closing the MLRepo, all data wil be lost. Therefore this should be only considered for testing or rapid and dirty prototyping. Note that in this case, the JobRunner 
used is the :py:class:`pailab.job_runner.job_runner.SimpleJobRunner` which simply runs all jobs sequential on the local machine in the same python thread the MLRepo has been constructed (synchronously).


Disk
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
To initialize an MLRepo so that the objects are stored on disk, we need to setup th respectiv storages within the MLRepo. 
One way to achieve this is to define the respective configurations in a dictionary and initialize the MLRepo with this dictionary.
An example is given 


.. literalinclude:: ../../tests/repo_test.py
    :language: python
    :start-after: diskhandlerconfig
    :end-before: end diskhandlerconfig

First we see that there is a user and also a workspace defined in the dictionary. The workspace is a directory where the configuration and settings are stored so that when you
instantiate the MLRepo again, you just need to specify the workspace and not the whole settings again.
The RepoStore used within the MLRepo is defined via the dictionary belonging to the repo_store key. Here we see that the configuration consists of describin the type of store
(here we use the disk_handler which simply stores the objects on disk) and the settings for this storage. In our example the objects are stored in json format in the 
folder example_1/objects.
The NumpyStore internally used is selected so that the big data will be stored in hdf5 files.

Now we simply instantiate the MLRepo using this configuration.


.. literalinclude:: ../../tests/repo_test.py
    :language: python
    :start-after: instantiate diskhandler
    :end-before: end instantiate diskhandler

To instantiate the MLRepo and directly save the respective config you have to set the parameter save_config

.. literalinclude:: ../../tests/repo_test.py
    :language: python
    :start-after: instantiate diskhandler save config
    :end-before: end instantiate diskhandler save config

Saving the config you may instantiate the MLRepo another time simply by 

.. literalinclude:: ../../tests/repo_test.py
    :language: python
    :start-after: instantiate with workspace
    :end-before: end instantiate with workspace



git
~~~~~~~~~~~~~~~~~~~~~~
The previous example stored the objects simply as json files on disk. There is the possibility to use git to manage the files. Here, you just have to replace the type by 'git_handler',
i.e. just change in the configuration dictionary above the type from 'disk_handler' to 'git_handler'. 
The MLRepo will then use the :py:class:`pailab.ml_repo.git_handler.RepoObjectGitStorage` as repo.

If you have a remote git repository which you want to use as a remote, you have to clone the repository first and then specify the directory of the cloned repo 
as directory of the git_handler.


Adding objects
----------------------------------
The repo works 